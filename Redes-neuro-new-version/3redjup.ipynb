{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eb997ff-3731-42b6-8c9d-942dd36b3b4e",
   "metadata": {},
   "source": [
    "# Importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21cb7b91-58b9-4e96-80c1-a82cce445419",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c97cc6-d0c2-4667-a876-cc5dac73dadd",
   "metadata": {},
   "source": [
    "# Recorrer la lista de números de prueba y leer las imágenes correspondientes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b19852-9f37-4497-b2cf-480ced11a3fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeros_prueba = range(0,10)\n",
    "imagenes = []\n",
    "etiquetas_imagenes = []\n",
    "\n",
    "num = 0\n",
    "guardar = str()\n",
    "\n",
    "#0.28 0.28 0,1       0.28 29.56 0,2\n",
    "for number in numeros_prueba:\n",
    "    imgReaded= f'grilla{str(number)}.jpg'\n",
    "    img = cv2.imread(imgReaded, cv2.IMREAD_GRAYSCALE)\n",
    "    for i in range(0,280*11,28):\n",
    "        ini_ver = i \n",
    "        fin_ver = i+27\n",
    "        for j in range (0,280,28):\n",
    "            ini_hor = j\n",
    "            fin_hor = j+27\n",
    "            #num+=1\n",
    "            #guardar = str(num)+\".jpg\"\n",
    "            img_numero = img[ini_ver:fin_ver, ini_hor:fin_hor].copy()\n",
    "            img_numero = cv2.resize(img_numero, (28, 28))\n",
    "            img_numero = cv2.bitwise_not(img_numero)\n",
    "            imagenes.append(img_numero)\n",
    "            etiquetas_imagenes.append(number)\n",
    "            #cv2.imwrite(guardar ,img[ini_ver:fin_ver, ini_hor:fin_hor])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92095615-5e72-417b-9c86-f689e4625f19",
   "metadata": {},
   "source": [
    "# Convertir las listas de imágenes y etiquetas en matrices numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8798e83a-e932-43bc-9d44-5d82272564ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imagenes = np.array(imagenes)\n",
    "etiquetas_imagenes = np.array(etiquetas_imagenes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71227ea1-bea7-4c90-a1c8-a330c21ef041",
   "metadata": {},
   "source": [
    "# Definir el modelo de la red neuronal y compilarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9235be13-5154-4887-8b8d-0b80281f4b10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelo = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)), # Capa de entrada que aplana las imágenes de 28x28 píxeles a un vector de 784 elementos\n",
    "    tf.keras.layers.Dense(1545, activation='relu'), # Capa oculta con 128 neuronas y función de activación ReLU\n",
    "\n",
    "    #tf.keras.layers.Dense(128*5, activation='relu'), # Capa oculta con 128 neuronas y función de activación ReLU\n",
    "\n",
    "    tf.keras.layers.Dense(10) # Capa de salida con 10 neuronas (una por cada número)\n",
    "])\n",
    "\n",
    "# Compilar el modelo con una función de pérdida y un optimizador\n",
    "modelo.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03539621-9d05-4d41-958e-1a757792ebf3",
   "metadata": {},
   "source": [
    "# Ajustar el modelo a las imágenes de entrenamiento y evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d51e0d50-7b0f-44f4-8f33-bf7a61d94085",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "344/344 [==============================] - 4s 9ms/step - loss: 10.7049 - accuracy: 0.8348\n",
      "Epoch 2/10\n",
      "344/344 [==============================] - 3s 9ms/step - loss: 0.9287 - accuracy: 0.9256\n",
      "Epoch 3/10\n",
      "344/344 [==============================] - 3s 9ms/step - loss: 0.7406 - accuracy: 0.9349\n",
      "Epoch 4/10\n",
      "344/344 [==============================] - 3s 9ms/step - loss: 0.7479 - accuracy: 0.9424\n",
      "Epoch 5/10\n",
      "344/344 [==============================] - 3s 9ms/step - loss: 0.7368 - accuracy: 0.9439\n",
      "Epoch 6/10\n",
      "344/344 [==============================] - 3s 9ms/step - loss: 0.6984 - accuracy: 0.9480\n",
      "Epoch 7/10\n",
      "344/344 [==============================] - 3s 9ms/step - loss: 0.4818 - accuracy: 0.9593\n",
      "Epoch 8/10\n",
      "344/344 [==============================] - 3s 9ms/step - loss: 0.7117 - accuracy: 0.9527\n",
      "Epoch 9/10\n",
      "344/344 [==============================] - 3s 10ms/step - loss: 0.5769 - accuracy: 0.9587\n",
      "Epoch 10/10\n",
      "344/344 [==============================] - 4s 11ms/step - loss: 0.4883 - accuracy: 0.9654\n",
      "344/344 [==============================] - 1s 2ms/step - loss: 0.7254 - accuracy: 0.9550\n",
      "Pérdida en el conjunto de prueba: 0.7253962755203247\n",
      "Precisión en el conjunto de prueba: 0.9549999833106995\n"
     ]
    }
   ],
   "source": [
    "modelo.fit(imagenes, etiquetas_imagenes, epochs=10)\n",
    "\n",
    "resultado = modelo.evaluate(imagenes, etiquetas_imagenes)\n",
    "print('Pérdida en el conjunto de prueba:', resultado[0])\n",
    "print('Precisión en el conjunto de prueba:', resultado[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac9916d-efa1-427e-a9d9-2fd3cb5cffd3",
   "metadata": {},
   "source": [
    "# Leer una nueva imagen, procesarla y hacer una predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96ede023-51f5-4c98-aa27-bfc026015491",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real: 1\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "El número predicho es: 1\n"
     ]
    }
   ],
   "source": [
    "print('Real: 1')\n",
    "img_nueva = cv2.imread(\"1prueba.jpg\", 0)\n",
    "\n",
    "# Redimensionar la imagen a 28x28 píxeles\n",
    "img_nueva = cv2.resize(img_nueva, (28, 28))\n",
    "img_nueva = cv2.bitwise_not(img_nueva)\n",
    "\n",
    "\n",
    "# Invertir los colores de la imagen\n",
    "#img_nueva = cv2.bitwise_not(img_nueva)\n",
    "\n",
    "# convertir la imagen a un tensor y normalizar los valores de píxeles\n",
    "#img_prueba = tf.keras.utils.normalize(img_nueva.reshape((1, 28, 28, 1)), axis=1)\n",
    "\n",
    "# Escalar los valores de los píxeles a un rango de 0 a 1\n",
    "img_nueva = img_nueva.astype('float32') / 255\n",
    "\n",
    "# Aplanar la imagen en un vector de 784 elementos\n",
    "img_nueva = img_nueva.reshape(1, 28, 28)\n",
    "\n",
    "\n",
    "\n",
    "# Hacer una predicción sobre la imagen nueva\n",
    "prediccion = modelo.predict(img_nueva)\n",
    "\n",
    "# Obtener el número predicho como el índice con la mayor probabilidad\n",
    "numero_predicho = np.argmax(prediccion)\n",
    "\n",
    "print('El número predicho es:', numero_predicho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1079b1ac-25b5-45c3-bf6b-5816e91a479e",
   "metadata": {},
   "source": [
    "# Leer una nueva imagen, procesarla y hacer una predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7252afc-4f2c-49ee-bc14-0b8233bbe3a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real: 3\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "El número predicho es: 3\n"
     ]
    }
   ],
   "source": [
    "print('Real: 3')\n",
    "\n",
    "img_nueva = cv2.imread(\"3-2prueba.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "img_nueva = cv2.bitwise_not(img_nueva)\n",
    "\n",
    "# Redimensionar la imagen a 28x28 píxeles\n",
    "img_nueva = cv2.resize(img_nueva, (28, 28))\n",
    "\n",
    "# Invertir los colores de la imagen\n",
    "#img_nueva = cv2.bitwise_not(img_nueva)\n",
    "\n",
    "# Escalar los valores de los píxeles a un rango de 0 a 1\n",
    "img_nueva = img_nueva.astype('float32') / 255.0\n",
    "\n",
    "# Aplanar la imagen en un vector de 784 elementos\n",
    "img_nueva = img_nueva.reshape(1, 784)\n",
    "\n",
    "# Hacer una predicción sobre la imagen nueva\n",
    "prediccion = modelo.predict(img_nueva)\n",
    "\n",
    "# Obtener el número predicho como el índice con la mayor probabilidad\n",
    "numero_predicho = np.argmax(prediccion)\n",
    "\n",
    "print('El número predicho es:', numero_predicho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fc9324-7000-4a91-85cd-4722bd8c1f7d",
   "metadata": {},
   "source": [
    "# Leer una nueva imagen, procesarla y hacer una predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45a57dc1-64bf-4fdd-a96d-124259190a9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real: 8\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "El número predicho es: 8\n"
     ]
    }
   ],
   "source": [
    "print('Real: 8')\n",
    "\n",
    "img_nueva = cv2.imread(\"8-1prueba.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "img_nueva = cv2.bitwise_not(img_nueva)\n",
    "\n",
    "# Redimensionar la imagen a 28x28 píxeles\n",
    "img_nueva = cv2.resize(img_nueva, (28, 28))\n",
    "\n",
    "# Invertir los colores de la imagen\n",
    "#img_nueva = cv2.bitwise_not(img_nueva)\n",
    "\n",
    "# Escalar los valores de los píxeles a un rango de 0 a 1\n",
    "img_nueva = img_nueva.astype('float32') / 255.0\n",
    "\n",
    "# Aplanar la imagen en un vector de 784 elementos\n",
    "img_nueva = img_nueva.reshape(1, 784)\n",
    "\n",
    "# Hacer una predicción sobre la imagen nueva\n",
    "prediccion = modelo.predict(img_nueva)\n",
    "\n",
    "# Obtener el número predicho como el índice con la mayor probabilidad\n",
    "numero_predicho = np.argmax(prediccion)\n",
    "\n",
    "print('El número predicho es:', numero_predicho)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb700da5-8a8c-4865-9102-85b9dfad0e3d",
   "metadata": {},
   "source": [
    "# Leer una nueva imagen, procesarla y hacer una predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea600a09-b9c9-4ed8-a4de-ec7c9c9c25d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real: 9\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "El número predicho es: 4\n"
     ]
    }
   ],
   "source": [
    "print('Real: 9')\n",
    "\n",
    "img_nueva = cv2.imread(\"9-3prueba.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "img_nueva = cv2.bitwise_not(img_nueva)\n",
    "\n",
    "# Redimensionar la imagen a 28x28 píxeles\n",
    "img_nueva = cv2.resize(img_nueva, (28, 28))\n",
    "\n",
    "# Invertir los colores de la imagen\n",
    "#img_nueva = cv2.bitwise_not(img_nueva)\n",
    "\n",
    "# Escalar los valores de los píxeles a un rango de 0 a 1\n",
    "img_nueva = img_nueva.astype('float32') / 255.0\n",
    "\n",
    "# Aplanar la imagen en un vector de 784 elementos\n",
    "img_nueva = img_nueva.reshape(1, 784)\n",
    "\n",
    "# Hacer una predicción sobre la imagen nueva\n",
    "prediccion = modelo.predict(img_nueva)\n",
    "\n",
    "# Obtener el número predicho como el índice con la mayor probabilidad\n",
    "numero_predicho = np.argmax(prediccion)\n",
    "\n",
    "print('El número predicho es:', numero_predicho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a221e10b-936e-4c9b-9eb8-4fd5d631bc30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
